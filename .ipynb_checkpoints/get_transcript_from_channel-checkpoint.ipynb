{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run this code if you have not install nltk\n",
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=1058491395494-4qbe4hpnb5akqgcfervr8si3ufe0fgk5.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.readonly&state=wkSjqyiafBO3nkNJ2921MSttI85FBA&prompt=consent&access_type=offline\n",
      "Enter the authorization code: 4/3QFYNiYadCmedoPDHXns11QP5Set47kauhHcp0FmU3F3uWTVgIieyxQ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "# scopes = [\"https://www.googleapis.com/auth/youtube.force-ssl\"]\n",
    "\n",
    "# Disable OAuthlib's HTTPS verification when running locally.\n",
    "# *DO NOT* leave this option enabled in production.\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "client_secrets_file = \"client_secret_Thu.json\"\n",
    "\n",
    "# Get credentials and create an API client\n",
    "flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(client_secrets_file, scopes)\n",
    "credentials = flow.run_console()\n",
    "youtube = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to get video ids from channel url\n",
    "# params: url - string to a youtube channel\n",
    "# return video_ids - list\n",
    "# raise ValueError when input is invalid channel id\n",
    "def get_vidids_from_channel(url):\n",
    "    if not url.startswith(\"https://www.youtube.com/channel/\"):\n",
    "        raise ValueError(\"input url not a url\")\n",
    "    else:\n",
    "        channel_id = url[len(\"https://www.youtube.com/channel/\"):]\n",
    "    \n",
    "    # get the playlist of upload videos by the channel\n",
    "    request = youtube.channels().list(\n",
    "        part=\"contentDetails\",\n",
    "        id=channel_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    if \"items\" not in response:\n",
    "        raise ValueError(\"channel id not valid\")\n",
    "    \n",
    "    upload_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "    #print(upload_playlist_id)\n",
    "    \n",
    "    # retrieve a list of video ids from upload playlist\n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"contentDetails\",\n",
    "        maxResults=10,\n",
    "        playlistId=upload_playlist_id\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    items = response[\"items\"]\n",
    "    video_ids = []\n",
    "    for each in items:\n",
    "        video_ids.append(each[\"contentDetails\"][\"videoId\"])\n",
    "        \n",
    "    #print(video_ids)\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to get transcript from video ids\n",
    "# params: video_ids - a list of video ids\n",
    "# the data being written into sample_caption is clean\n",
    "def get_transcript_from_vidids(video_ids):\n",
    "    script = []\n",
    "    for i in range(len(video_ids)):\n",
    "        script.append(YouTubeTranscriptApi.get_transcript(video_ids[i], languages = ['en']))\n",
    "    #print(script)\n",
    "\n",
    "    with open('sample_caption.txt',\"w\") as filehandle:\n",
    "        for i in range(len(script)):\n",
    "            for listitem in script[i]:\n",
    "                # removing punctuation and numbers and brackets\n",
    "                filehandle.write(listitem.get('text')+\" \")\n",
    "                \n",
    "                listitem = listitem.get('text').lower()+\" \"\n",
    "                listitem = re.sub('\\[.*?\\]','', listitem)\n",
    "                listitem = re.sub('\\(.*?\\)','', listitem)\n",
    "                listitem = re.sub('[%s]' % re.escape(string.punctuation), '', listitem)\n",
    "                listitem = re.sub('\\w*\\d\\w','', listitem)\n",
    "                listitem = re.sub('\\d+', '', listitem)\n",
    "                \n",
    "                # removing stop words\n",
    "                word_tokens = listitem.split(' ')\n",
    "                filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "                listitem = \"\"\n",
    "                for each in filtered_sentence:\n",
    "                    listitem += each + \" \"\n",
    "                    \n",
    "                filehandle.write(listitem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_caption():\n",
    "    unclean_file = open('sample_caption.txt','r')\n",
    "    raw_text = unclean_file.read().lower()\n",
    "    raw_text = re.sub('\\[.*?\\]','', raw_text)\n",
    "    raw_text = re.sub('\\(.*?\\)','', raw_text)\n",
    "    raw_text = re.sub('[%s]' % re.escape(string.punctuation), '', raw_text)\n",
    "    raw_text = re.sub('\\w*\\d\\w','', raw_text)\n",
    "    raw_text = re.sub('\\d+', '', raw_text)\n",
    "    \n",
    "    word_tokens = word_tokenize(raw_text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    \n",
    "    clean_file = open('clean_caption.txt', 'w')\n",
    "    for each in filtered_sentence:\n",
    "        clean_file.write(each + \" \")\n",
    "    \n",
    "    unclean_file.close()\n",
    "    clean_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4d7d117348f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-4d7d117348f6>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mvid_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_vidids_from_channel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.youtube.com/channel/UCbAwSkqJ1W_Eg7wr3cp5BUA\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mget_transcript_from_vidids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvid_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mclean_caption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#     get_vidids_from_channel(\"https://www.youtube.com/channel/UCG7RoGLCkUT7kauOBCRmVEg\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     get_vidids_from_channel(\"https://www.youtube.com/channel/UCGCVyTWogzQ4D170BLy2Arw\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-362e76af3247>\u001b[0m in \u001b[0;36mclean_caption\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mword_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mfiltered_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mclean_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clean_caption.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-362e76af3247>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mword_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mfiltered_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mclean_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clean_caption.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop_words' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    vid_ids = get_vidids_from_channel(\"https://www.youtube.com/channel/UCbAwSkqJ1W_Eg7wr3cp5BUA\")\n",
    "    get_transcript_from_vidids(vid_ids)\n",
    "    clean_caption()\n",
    "#     get_vidids_from_channel(\"https://www.youtube.com/channel/UCG7RoGLCkUT7kauOBCRmVEg\")\n",
    "#     get_vidids_from_channel(\"https://www.youtube.com/channel/UCGCVyTWogzQ4D170BLy2Arw\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
